{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast training with MONAI features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disclaimer\n",
    "\n",
    "This tutorial was adapted from the official MONAI [\"Fast training tutorial\"](https://github.com/Project-MONAI/tutorials/blob/main/acceleration/fast_training_tutorial.ipynb).]\n",
    "\n",
    "This tutorial shows a regular PyTorch training program and a MONAI optimized training program, and compares the performance.  \n",
    "\n",
    "Depending on the hardware this tutorial is run on, speed-ups on the order of 10-20x or more can be obtained per epoch on a single-GPU. With additional algorithmic improvements, a desired target Dice overlap (e.g. 0.94) on the MSD Spleen-CT dataset can be obtained 100-200x times faster.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nvahmadi/NVIDIA_CAMP_Workshop/blob/main/06_fast_training_tutorial.ipynb)\n",
    "\n",
    "#### Learning goals\n",
    "For MONAI fast training, your task is to introduce the following 6 acceleration features into the `train_process()` function below.\n",
    "\n",
    "Search (Ctrl+F) for the tag TODO-N to quick-jump to the correct location(s) where to solve the task.\n",
    "\n",
    "* TODO-1: `AMP` (auto mixed precision): AMP is an important feature in PyTorch since v1.6, and NVIDIA CUDA 11 added strong support for AMP and significantly improved training speed. Check the [AMP website](https://developer.nvidia.com/automatic-mixed-precision) (section \"PyTorch\") for the 7 lines of code that are required to use AMP and gradient scaling in your optimization loop (note: the mentioned `autocast()` function is part of the torch module `torch.cuda.amp.autocast()`). (Solution __[here](step1_solution.py)__).\n",
    "* TODO-2: `CacheDataset`: The [CacheDataset](https://docs.monai.io/en/stable/data.html#cachedataset) class provides a cache mechanism that can load and cache all or parts of the training data, including the results from all deterministic transforms. (Solution __[here](step2_solution.py)__).\n",
    "* TODO-3: `ToDeviced`: The [ToDeviced](https://docs.monai.io/en/stable/transforms.html#todeviced) class moves batch data to GPU. Combined with `CacheDataset`, all following random transforms are executed on GPU directly. This avoids CPU -> GPU syncs in every epoch. Please note that not all the MONAI transforms support GPU operation so far, this is a continuous work-in-progress. (Solution __[here](step3_solution.py)__).\n",
    "* TODO-4: `ThreadDataLoader`: The [ThreadDataLoader](https://docs.monai.io/en/stable/data.html#threaddataloader) class uses multi-threads instead of multi-processing, which yields faster results than `DataLoader` in light-weight task. We can use it here as we already cached the results of most computation, and remaining transforms are executed on the GPU. (Solution __[here](step4_solution.py)__).\n",
    "* TODO-5: `DiceCE` loss function: The [DiceCE](https://docs.monai.io/en/stable/losses.html#diceceloss) class computes both Dice loss and Cross Entropy Loss, and returns a weighted sum of these two losses. (Solution __[here](step5_solution.py)__).\n",
    "* TODO-6: `Novograd` optimizer: The [Novograd](https://docs.monai.io/en/stable/optimizers.html#monai.optimizers.Novograd) optimizer is based on the paper \"Stochastic Gradient Methods with Layer-wise Adaptive Moments for Training of Deep Networks\" ([arXiv](https://arxiv.org/pdf/1905.11286.pdf)). It can simply replace Adam, with an increased learning rate (e.g. 10x). (Solution __[here](step6_solution.py)__).\n",
    "\n",
    "Implement these steps one by one. Once done, run e.g. 5 epochs of training in the cell below to evaluate the acceleration. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel, tqdm]\"\n",
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.0.0+38.g32a237a7\n",
      "Numpy version: 1.22.2\n",
      "Pytorch version: 1.13.0a0+d0d6b1f\n",
      "MONAI flags: HAS_EXT = True, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 32a237a7959e4890a963481c23baff84b95a253b\n",
      "MONAI __file__: /opt/monai/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.10\n",
      "Nibabel version: 4.0.2\n",
      "scikit-image version: 0.19.3\n",
      "Pillow version: 9.0.1\n",
      "Tensorboard version: 2.10.0\n",
      "gdown version: 4.5.1\n",
      "TorchVision version: 0.14.0a0\n",
      "tqdm version: 4.64.1\n",
      "lmdb version: 1.3.0\n",
      "psutil version: 5.9.2\n",
      "pandas version: 1.4.4\n",
      "einops version: 0.5.0\n",
      "transformers version: 4.21.3\n",
      "mlflow version: 1.29.0\n",
      "pynrrd version: 1.0.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2020 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import (\n",
    "    CacheDataset,\n",
    "    DataLoader,\n",
    "    ThreadDataLoader,\n",
    "    Dataset,\n",
    "    decollate_batch,\n",
    ")\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.losses import DiceLoss, DiceCELoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.layers import Norm\n",
    "from monai.networks.nets import UNet\n",
    "from monai.optimizers import Novograd\n",
    "from monai.transforms import (\n",
    "    EnsureChannelFirstd,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    FgBgToIndicesd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.utils import get_torch_version_tuple, set_determinism\n",
    "\n",
    "print_config()\n",
    "\n",
    "if get_torch_version_tuple() < (1, 6):\n",
    "    raise RuntimeError(\n",
    "        \"AMP feature only exists in PyTorch version greater than v1.6.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data directory\n",
    "\n",
    "You can specify a directory with the `MONAI_DATA_DIRECTORY` environment variable.  \n",
    "This allows you to save results and reuse downloads.  \n",
    "If not specified a temporary directory will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root dir is: ./data\n"
     ]
    }
   ],
   "source": [
    "#directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "#root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "root_dir = './data' #os.getenv(\"WORKDIR\")\n",
    "print(f\"root dir is: {root_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset\n",
    "\n",
    "Downloads and extracts the Decathlon Spleen dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Task09_Spleen' directory exists. Data download skipped.\n"
     ]
    }
   ],
   "source": [
    "#\"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task09_Spleen.tar\"\n",
    "md5 = \"410d4a301da4e5b2f6f86ec3ddba524e\"\n",
    "compressed_file = os.path.join(root_dir, \"Task09_Spleen.tar\")\n",
    "data_root = os.path.join(root_dir, \"Task09_Spleen\")\n",
    "if not os.path.exists(data_root):\n",
    "    download_and_extract(compressed_file, compressed_file, root_dir, md5)\n",
    "    print(\"Data downloaded and extracted to 'Task09_Spleen' directory.\")\n",
    "else:\n",
    "    print(\"'Task09_Spleen' directory exists. Data download skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set MSD Spleen dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example dicts in training dataset (N=3):\n",
      "\n",
      "[{'image': './data/Task09_Spleen/imagesTr/spleen_10.nii.gz',\n",
      "  'label': './data/Task09_Spleen/labelsTr/spleen_10.nii.gz'},\n",
      " {'image': './data/Task09_Spleen/imagesTr/spleen_12.nii.gz',\n",
      "  'label': './data/Task09_Spleen/labelsTr/spleen_12.nii.gz'},\n",
      " {'image': './data/Task09_Spleen/imagesTr/spleen_13.nii.gz',\n",
      "  'label': './data/Task09_Spleen/labelsTr/spleen_13.nii.gz'}]\n"
     ]
    }
   ],
   "source": [
    "train_images = sorted(\n",
    "    glob.glob(os.path.join(data_root, \"imagesTr\", \"*.nii.gz\"))\n",
    ")\n",
    "train_labels = sorted(\n",
    "    glob.glob(os.path.join(data_root, \"labelsTr\", \"*.nii.gz\"))\n",
    ")\n",
    "data_dicts = [\n",
    "    {\"image\": image_name, \"label\": label_name}\n",
    "    for image_name, label_name in zip(train_images, train_labels)\n",
    "]\n",
    "train_files, val_files = data_dicts[:-9], data_dicts[-9:]\n",
    "\n",
    "print('\\nExample dicts in training dataset (N=3):\\n')\n",
    "pprint(train_files[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup transforms for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformations(fast=False, device='cuda:0'):\n",
    "    train_transforms = [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-57,\n",
    "            a_max=164,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        # pre-compute foreground and background indexes\n",
    "        # and cache them to accelerate training\n",
    "        FgBgToIndicesd(\n",
    "            keys=\"label\",\n",
    "            fg_postfix=\"_fg\",\n",
    "            bg_postfix=\"_bg\",\n",
    "            image_key=\"image\",\n",
    "        ),\n",
    "    ]\n",
    "    if fast:\n",
    "        # TODO-3-Part1/2: Augmentation on the GPU\n",
    "        # NB: move the data to GPU using EnsureTyped() transform (set: track_meta=False)\n",
    "        #     Do not forget the validation transforms below.\n",
    "        train_transforms.append(\n",
    "            EnsureTyped(keys=[\"image\", \"label\"], device=device, track_meta=False)\n",
    "        )\n",
    "        \n",
    "    train_transforms.append(\n",
    "        # randomly crop out patch samples from big\n",
    "        # image based on pos / neg ratio\n",
    "        # the image centers of negative samples\n",
    "        # must be in valid image area\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(96, 96, 96),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            fg_indices_key=\"label_fg\",\n",
    "            bg_indices_key=\"label_bg\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    val_transforms = [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-57,\n",
    "            a_max=164,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    "    if fast:\n",
    "        # TODO-3-Part2/2: Augmentation on the GPU\n",
    "        # NB: move the data to GPU using ToDeviced() transform\n",
    "        val_transforms.append(\n",
    "            EnsureTyped(keys=[\"image\", \"label\"], device=device, track_meta=False)\n",
    "        )\n",
    "\n",
    "    return Compose(train_transforms), Compose(val_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the training progress\n",
    "The cell below implements a typical PyTorch training loop, with regular classes like `Dataset`, `DataLoader`, `Adam` optimizer and `Dice` loss to train the model.\n",
    "\n",
    "There are several locations where your job will be to implement various forms of acceleration (see task description in cells below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_process(fast=False, max_epochs=100):\n",
    "    learning_rate = 2e-4\n",
    "    val_interval = 1  # do validation for every epoch\n",
    "\n",
    "    train_trans, val_trans = transformations(fast=fast)\n",
    "    # set CacheDataset, ThreadDataLoader and DiceCE loss for MONAI fast training\n",
    "    if fast:\n",
    "        # TODO-2: Replace regular `DataLoader` with `ThreadDataLoader`\n",
    "        # NB: as `RandCropByPosNegLabeld` crops from the cached content and `deepcopy`\n",
    "        # the crop area instead of modifying the cached value, we can set `copy_cache=False`\n",
    "        # to avoid unnecessary deepcopy of cached content in `CacheDataset`\n",
    "        train_ds = CacheDataset(\n",
    "            data=train_files,\n",
    "            transform=train_trans,\n",
    "            cache_rate=1.0,\n",
    "            num_workers=8,\n",
    "            copy_cache=False,\n",
    "        )\n",
    "        val_ds = CacheDataset(\n",
    "            data=val_files, transform=val_trans, cache_rate=1.0, num_workers=4, copy_cache=False\n",
    "        )\n",
    "        \n",
    "        # TODO-4: Instead of regular `DataLoader` use `ThreadDataLoader`\n",
    "        # NB: no multi-workers argument, because `ThreadDataLoader` works with multi-threads\n",
    "        train_loader = ThreadDataLoader(train_ds, num_workers=0, batch_size=4, shuffle=True)\n",
    "        val_loader = ThreadDataLoader(val_ds, num_workers=0, batch_size=1)\n",
    "        \n",
    "        # TODO-5: Use DiceCE loss instead of regular Dice loss.\n",
    "        loss_function = DiceCELoss(to_onehot_y=True, softmax=True, squared_pred=True, batch=True)\n",
    "        \n",
    "    else:\n",
    "        train_ds = Dataset(data=train_files, transform=train_trans)\n",
    "        val_ds = Dataset(data=val_files, transform=val_trans)\n",
    "        # num_worker=4 is the best parameter according to the test\n",
    "        train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4)\n",
    "        val_loader = DataLoader(val_ds, batch_size=1, num_workers=4)\n",
    "        loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    model = UNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=2,\n",
    "        channels=(16, 32, 64, 128, 256),\n",
    "        strides=(2, 2, 2, 2),\n",
    "        num_res_units=2,\n",
    "        norm=Norm.BATCH,\n",
    "    ).to(device)\n",
    "\n",
    "    post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=2)])\n",
    "    post_label = Compose([EnsureType(), AsDiscrete(to_onehot=2)])\n",
    "\n",
    "    dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "\n",
    "    # set Novograd optimizer for MONAI training\n",
    "    if fast:\n",
    "        \n",
    "        # TODO-1-Part1/2: Automatic Mixed Precision (AMP)\n",
    "        # NB: Initialize the AMP scaler\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "        \n",
    "        # TODO-6: Replace regular `Adam` optimizer with `Novograd`\n",
    "        # NB: Novograd paper suggests to use a bigger LR than Adam (use: learning_rate * 10),\n",
    "        #     because Adam does normalization by element-wise second moments\n",
    "        optimizer = Novograd(model.parameters(), learning_rate * 10)\n",
    "        \n",
    "    else:\n",
    "        optimizer = Adam(model.parameters(), learning_rate)\n",
    "\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    best_metrics_epochs_and_time = [[], [], []]\n",
    "    epoch_loss_values = []\n",
    "    metric_values = []\n",
    "    epoch_times = []\n",
    "    total_start = time.time()\n",
    "    for epoch in range(max_epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        step = 0\n",
    "        for batch_data in train_loader:\n",
    "            step_start = time.time()\n",
    "            step += 1\n",
    "            inputs, labels = (\n",
    "                batch_data[\"image\"].to(device),\n",
    "                batch_data[\"label\"].to(device),\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "            # set AMP for MONAI training\n",
    "            if fast:\n",
    "                # TODO-1-Part2/2: Automatic Mixed Precision (AMP)\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = loss_function(outputs, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                \n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_len = math.ceil(len(train_ds) / train_loader.batch_size)\n",
    "            print(\n",
    "                f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\"\n",
    "                f\" step time: {(time.time() - step_start):.4f}\"\n",
    "            )\n",
    "        epoch_loss /= step\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for val_data in val_loader:\n",
    "                    val_inputs, val_labels = (\n",
    "                        val_data[\"image\"].to(device),\n",
    "                        val_data[\"label\"].to(device),\n",
    "                    )\n",
    "                    roi_size = (160, 160, 160)\n",
    "                    sw_batch_size = 4\n",
    "                    # set AMP for MONAI validation\n",
    "                    if fast:\n",
    "                        with torch.cuda.amp.autocast():\n",
    "                            val_outputs = sliding_window_inference(\n",
    "                                val_inputs, roi_size, sw_batch_size, model\n",
    "                            )\n",
    "                    else:\n",
    "                        val_outputs = sliding_window_inference(\n",
    "                            val_inputs, roi_size, sw_batch_size, model\n",
    "                        )\n",
    "                    val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "                    val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "                    dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "                metric = dice_metric.aggregate().item()\n",
    "                dice_metric.reset()\n",
    "                metric_values.append(metric)\n",
    "                if metric > best_metric:\n",
    "                    best_metric = metric\n",
    "                    best_metric_epoch = epoch + 1\n",
    "                    best_metrics_epochs_and_time[0].append(best_metric)\n",
    "                    best_metrics_epochs_and_time[1].append(best_metric_epoch)\n",
    "                    best_metrics_epochs_and_time[2].append(\n",
    "                        time.time() - total_start\n",
    "                    )\n",
    "                    torch.save(model.state_dict(), \"best_metric_model.pth\")\n",
    "                    print(\"saved new best metric model\")\n",
    "                print(\n",
    "                    f\"current epoch: {epoch + 1} current\"\n",
    "                    f\" mean dice: {metric:.4f}\"\n",
    "                    f\" best mean dice: {best_metric:.4f}\"\n",
    "                    f\" at epoch: {best_metric_epoch}\"\n",
    "                )\n",
    "        print(\n",
    "            f\"time consuming of epoch {epoch + 1} is:\"\n",
    "            f\" {(time.time() - epoch_start):.4f}\"\n",
    "        )\n",
    "        epoch_times.append(time.time() - epoch_start)\n",
    "\n",
    "    total_time = time.time() - total_start\n",
    "    print(\n",
    "        f\"train completed, best_metric: {best_metric:.4f}\"\n",
    "        f\" at epoch: {best_metric_epoch}\"\n",
    "        f\" total time: {total_time:.4f}\"\n",
    "    )\n",
    "    return (\n",
    "        max_epochs,\n",
    "        epoch_loss_values,\n",
    "        metric_values,\n",
    "        epoch_times,\n",
    "        best_metrics_epochs_and_time,\n",
    "        total_time,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable determinism and execute regular PyTorch training\n",
    "\n",
    "Run the cell below for a few epochs of training (e.g. `max_epochs = 3`). Observe and note down the training times per epoch.\n",
    "\n",
    "Once there is time (i.e. after the workshop), feel free to run a full convergence (i.e. max_epochs = 300) to lay a baseline for full training duration and epoch durations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 3\n",
    "set_determinism(seed=0)\n",
    "regular_start = time.time()\n",
    "(\n",
    "    epoch_num,\n",
    "    epoch_loss_values,\n",
    "    metric_values,\n",
    "    epoch_times,\n",
    "    best,\n",
    "    train_time,\n",
    ") = train_process(fast=False, max_epochs=max_epochs)\n",
    "total_time = time.time() - regular_start\n",
    "print(\n",
    "    f\"total time of {epoch_num} epochs with regular PyTorch training: {total_time:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable determinism and execute MONAI optimized training\n",
    "\n",
    "Run optimized training by setting the training `train_process(fast=True, ...)`.\n",
    "\n",
    "Once there is time (i.e. after the workshop), feel free to run a full convergence (e.g. `max_epochs = 300`) to be able to compare the final outcomes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 32/32 [00:37<00:00,  1.17s/it]\n",
      "Loading dataset: 100%|██████████| 9/9 [00:08<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/3\n",
      "1/8, train_loss: 1.6571 step time: 0.4328\n",
      "2/8, train_loss: 1.6707 step time: 0.1587\n",
      "3/8, train_loss: 1.6858 step time: 0.1515\n",
      "4/8, train_loss: 1.6141 step time: 0.1556\n",
      "5/8, train_loss: 1.5698 step time: 0.1576\n",
      "6/8, train_loss: 1.5664 step time: 0.1576\n",
      "7/8, train_loss: 1.5063 step time: 0.1434\n",
      "8/8, train_loss: 1.4235 step time: 0.1323\n",
      "epoch 1 average loss: 1.5867\n",
      "saved new best metric model\n",
      "current epoch: 1 current mean dice: 0.2280 best mean dice: 0.2280 at epoch: 1\n",
      "time consuming of epoch 1 is: 2.2990\n",
      "----------\n",
      "epoch 2/3\n",
      "1/8, train_loss: 1.3676 step time: 0.1571\n",
      "2/8, train_loss: 1.3337 step time: 0.1647\n",
      "3/8, train_loss: 1.2911 step time: 0.1699\n",
      "4/8, train_loss: 1.2463 step time: 0.1690\n",
      "5/8, train_loss: 1.1732 step time: 0.1701\n",
      "6/8, train_loss: 1.1400 step time: 0.1598\n",
      "7/8, train_loss: 1.1255 step time: 0.1443\n",
      "8/8, train_loss: 1.0530 step time: 0.1444\n",
      "epoch 2 average loss: 1.2163\n",
      "saved new best metric model\n",
      "current epoch: 2 current mean dice: 0.5035 best mean dice: 0.5035 at epoch: 2\n",
      "time consuming of epoch 2 is: 1.9879\n",
      "----------\n",
      "epoch 3/3\n",
      "1/8, train_loss: 0.9681 step time: 0.1556\n",
      "2/8, train_loss: 0.9588 step time: 0.1638\n",
      "3/8, train_loss: 0.8919 step time: 0.1520\n",
      "4/8, train_loss: 0.9012 step time: 0.1683\n",
      "5/8, train_loss: 0.8713 step time: 0.1641\n",
      "6/8, train_loss: 0.8129 step time: 0.1585\n",
      "7/8, train_loss: 0.7900 step time: 0.1445\n",
      "8/8, train_loss: 0.7865 step time: 0.1428\n",
      "epoch 3 average loss: 0.8726\n",
      "saved new best metric model\n",
      "current epoch: 3 current mean dice: 0.5186 best mean dice: 0.5186 at epoch: 3\n",
      "time consuming of epoch 3 is: 1.9383\n",
      "train completed, best_metric: 0.5186 at epoch: 3 total time: 6.2252\n",
      "total time of 3 epochs with MONAI fast training: 6.2252, time of preparing cache: 46.3303\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 3\n",
    "set_determinism(seed=0)\n",
    "monai_start = time.time()\n",
    "(\n",
    "    epoch_num,\n",
    "    m_epoch_loss_values,\n",
    "    m_metric_values,\n",
    "    m_epoch_times,\n",
    "    m_best,\n",
    "    m_train_time,\n",
    ") = train_process(fast=True, max_epochs=max_epochs)\n",
    "m_total_time = time.time() - monai_start\n",
    "print(\n",
    "    f\"total time of {epoch_num} epochs with MONAI fast training: {m_train_time:.4f},\"\n",
    "    f\" time of preparing cache: {(m_total_time - m_train_time):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training loss and validation metrics\n",
    "\n",
    "This cell plots the training metrics and ideally should be executed after a full training run (with e.g. `max_epochs = 300`).\n",
    "\n",
    "You can see examples of all following plots at the bottom of the official [Fast Training Tutorial](https://github.com/Project-MONAI/tutorials/blob/master/acceleration/fast_training_tutorial.ipynb), obtained after 300 epochs on a V100 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"train\", (12, 12))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"Regular Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.grid(alpha=0.4, linestyle=\":\")\n",
    "plt.plot(x, y, color=\"red\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"Regular Val Mean Dice\")\n",
    "x = [i + 1 for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(alpha=0.4, linestyle=\":\")\n",
    "plt.plot(x, y, color=\"red\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"Fast Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(m_epoch_loss_values))]\n",
    "y = m_epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.grid(alpha=0.4, linestyle=\":\")\n",
    "plt.plot(x, y, color=\"green\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"Fast Val Mean Dice\")\n",
    "x = [i + 1 for i in range(len(m_metric_values))]\n",
    "y = m_metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(alpha=0.4, linestyle=\":\")\n",
    "plt.plot(x, y, color=\"green\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot total time and every epoch time\n",
    "\n",
    "This cell plots the training times and, as above, ideally should be executed after a full training run (with e.g. `max_epochs = 300`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Total Train Time(300 epochs)\")\n",
    "plt.bar(\n",
    "    \"regular PyTorch\", total_time, 1, label=\"Regular training\", color=\"red\"\n",
    ")\n",
    "plt.bar(\"Fast\", m_total_time, 1, label=\"Fast training\", color=\"green\")\n",
    "plt.ylabel(\"secs\")\n",
    "plt.grid(alpha=0.4, linestyle=\":\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Epoch Time\")\n",
    "x = [i + 1 for i in range(max_epochs)]\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"secs\")\n",
    "plt.plot(x, epoch_times, label=\"Regular training\", color=\"red\")\n",
    "plt.plot(x, m_epoch_times, label=\"Fast training\", color=\"green\")\n",
    "plt.grid(alpha=0.4, linestyle=\":\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "print('-------------------------------')\n",
    "print(f'Total speed-up: {total_time/m_total_time:.3f} x')\n",
    "print('-------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot total time to achieve metrics\n",
    "\n",
    "This cell plots the times and speed-ups until reaching target Dice values (i.e. 0.9/0.93/0.95/0.97). As above, this should be ideally executed after a full training run (with e.g. `max_epochs = 300`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_metric_time(threshold, best_values):\n",
    "    for i, v in enumerate(best_values[0]):\n",
    "        if v > threshold:\n",
    "            return best_values[2][i]\n",
    "    return -1\n",
    "\n",
    "\n",
    "def get_best_metric_epochs(threshold, best_values):\n",
    "    for i, v in enumerate(best_values[0]):\n",
    "        if v > threshold:\n",
    "            return best_values[1][i]\n",
    "    return -1\n",
    "\n",
    "\n",
    "def get_label(index):\n",
    "    if index == 0:\n",
    "        return \"Regular training\"\n",
    "    elif index == 1:\n",
    "        return \"Fast training\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "plt.figure(\"train\", (18, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Metrics Time\")\n",
    "plt.xlabel(\"secs\")\n",
    "plt.ylabel(\"best mean_dice\")\n",
    "plt.plot(best[2], best[0], label=\"Regular training\", color=\"red\")\n",
    "plt.plot(m_best[2], m_best[0], label=\"Fast training\", color=\"green\")\n",
    "plt.grid(alpha=0.4, linestyle=\":\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Typical Metrics Time\")\n",
    "plt.xlabel(\"best mean_dice\")\n",
    "plt.ylabel(\"secs\")\n",
    "labels = [\"0.90\", \"0.90 \", \"0.93\", \"0.93 \", \"0.95\", \"0.95 \", \"0.97\", \"0.97 \"]\n",
    "x_values = [0.9, 0.9, 0.93, 0.93, 0.95, 0.95, 0.97, 0.97]\n",
    "for i, (l, x) in enumerate(zip(labels, x_values)):\n",
    "    value = int(get_best_metric_time(x, best if i % 2 == 0 else m_best))\n",
    "    color = \"red\" if i % 2 == 0 else \"green\"\n",
    "    plt.bar(l, value, 0.5, label=get_label(i), color=color)\n",
    "    plt.text(l, value, \"%s\" % value, ha=\"center\", va=\"bottom\")\n",
    "plt.grid(alpha=0.4, linestyle=\":\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Typical Metrics Epochs\")\n",
    "plt.xlabel(\"best mean_dice\")\n",
    "plt.ylabel(\"epochs\")\n",
    "for i, (l, x) in enumerate(zip(labels, x_values)):\n",
    "    value = int(get_best_metric_epochs(x, best if i % 2 == 0 else m_best))\n",
    "    color = \"red\" if i % 2 == 0 else \"green\"\n",
    "    plt.bar(l, value, 0.5, label=get_label(i), color=color)\n",
    "    plt.text(l, value, \"%s\" % value, ha=\"center\", va=\"bottom\")\n",
    "plt.grid(alpha=0.4, linestyle=\":\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup data directory\n",
    "\n",
    "Remove directory if a temporary was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you want to delete data.\n",
    "#if directory is None:\n",
    "#    shutil.rmtree(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In the above tutorial, you went through several steps of accelerating your segmentation model training. Running a full training until convergence (e.g. `max_epochs = 300`) probably takes too long for the scope of this workshop. \n",
    "\n",
    "In the official MONAI [\"Fast training tutorial\"](https://github.com/Project-MONAI/tutorials/blob/master/acceleration/fast_training_tutorial.ipynb), it is stated that with a V100 GPU, the developers are able to achieve training convergence at a validation mean dice of `0.95` within `1 minute`. This corresponds to an approximately `200x` speedup compared with the Pytorch regular implementation when achieving same metric. And every epoch is `20x` faster than regular training.\n",
    "\n",
    "There are more tips and tricks for accelerated training with MONAI. For more details, please visit the official [\"Fast Model Training Guide\"](https://github.com/Project-MONAI/tutorials/blob/master/acceleration/fast_model_training_guide.md) in the [MONAI tutorials](https://github.com/Project-MONAI/tutorials) GitHub repository. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
